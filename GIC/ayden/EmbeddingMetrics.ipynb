{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [{'logo': 'https://img.voxmarkets.co.uk/200/companies/59a86c741e14e00011c1b96a.png', 'timestamp': '2024-10-07 06:00:00.000', 'storyId': '7db60859-9317-4f63-97e9-611b36cacd35', 'storyHeadline': 'Tesco PLC - Transaction in Own Shares', 'summary': 'RNS Number: 0766 H Tesco PLC 07 October 2024. This information is provided by RNS, the news service of the London Stock Exchange. RNS is approved by the Financial Conduct Authority to act as a Primary Information Provider in the United Kingdom.', 'ticker': 'TSCO.L', 'issue_name': 'Tesco PLC', 'likes': 10}, {'logo': 'https://img.voxmarkets.co.uk/200/companies/59a86c741e14e00011c1b96a.png', 'timestamp': '2024-10-04 06:00:00.000', 'storyId': 'fb0cec80-48df-41c5-90da-7abe9f65d7c2', 'storyHeadline': 'Tesco PLC - Transaction in Own Shares', 'summary': 'RNS Number: 9045 G Tesco PLC 04 October 2024. This information is provided by RNS, the news service of the London Stock Exchange. RNS is approved by the Financial Conduct Authority to act as a Primary Information Provider in the United Kingdom.', 'ticker': 'TSCO.L', 'issue_name': 'Tesco PLC', 'likes': 7}, {'logo': 'https://img.voxmarkets.co.uk/200/companies/59a86c741e14e00011c1b96a.png', 'timestamp': '2024-10-03 14:00:00.000', 'storyId': '4ed272e1-c0c8-41af-9901-7df1be430dba', 'storyHeadline': 'Tesco PLC - Publication of Base Prospectus', 'summary': 'TESCO CORPORATE TREASURY SERVICES EUROPE DAC. Supplement dated 3 October 2024 to the Offering Circular dated 9 July 2024 of the Tesco PLC, Tesco Corporate Treasury Services PLC and Tesco Corporate Treasury Services Europe DAC Â£15,000,000,000 Euro Note Programme unconditionally and irrevocably guaranteed in the case of Notes issued by each of Tesco...', 'ticker': 'TSCO.L', 'issue_name': 'Tesco PLC', 'likes': 5}, {'logo': 'https://img.voxmarkets.co.uk/200/companies/59a86c741e14e00011c1b96a.png', 'timestamp': '2024-10-03 06:06:00.000', 'storyId': '79be11ec-d925-42ad-876c-3925cd854131', 'storyHeadline': 'Tesco Corp Treasury - Tesco PLC Interim Results 2024/25', 'summary': 'RNS Number: 8023 G Tesco Corporate Treasury Services 03 October 2024 3 October 2024. TESCO CORPORATE TREASURY SERVICES PLC. TESCO CORPORATE TREASURY SERVICES EUROPE DAC.', 'ticker': 'FE80.L', 'issue_name': 'Tesco PLC', 'likes': 3}, {'logo': 'https://img.voxmarkets.co.uk/200/companies/59a86c741e14e00011c1b96a.png', 'timestamp': '2024-10-03 06:00:00.000', 'storyId': 'f9798444-14f1-434e-8534-45ede39c20a4', 'storyHeadline': 'Tesco PLC - Transaction in Own Shares', 'summary': 'RNS Number: 7311 G Tesco PLC 03 October 2024. This information is provided by RNS, the news service of the London Stock Exchange. RNS is approved by the Financial Conduct Authority to act as a Primary Information Provider in the United Kingdom.', 'ticker': 'TSCO.L', 'issue_name': 'Tesco PLC', 'likes': 1}]\n",
      "Company Name: Tesco PLC\n",
      "Company Name: Tesco PLC\n",
      "Company Name: Tesco PLC\n",
      "Company Name: Tesco PLC\n",
      "Company Name: Tesco PLC\n"
     ]
    }
   ],
   "source": [
    "#API TESTS\n",
    "import os\n",
    "import requests\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "url = \"https://api.joinzeed.com/rns/company\"\n",
    "headers = {\n",
    "    \"x-api-key\": \"3cnEecHxDE8qgHsTTftFPa49V5N4q2t15k4s4pqu\"\n",
    "}\n",
    "params = {\n",
    "    \"ticker\": \"TSCO.L\",\n",
    "    \"number\": 5  # Fetch the latest RNS for this company\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    print(f\"Data: {data}\")\n",
    "    for entry in data:\n",
    "        company_name = entry.get(\"issue_name\", \"Unknown\")  # issueName represents the company name\n",
    "        print(f\"Company Name: {company_name}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in ./.venv/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.venv/lib/python3.11/site-packages (from keybert) (1.26.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in ./.venv/lib/python3.11/site-packages (from keybert) (13.9.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in ./.venv/lib/python3.11/site-packages (from keybert) (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in ./.venv/lib/python3.11/site-packages (from keybert) (3.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.45.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (2.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in ./.venv/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (0.25.1)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (10.4.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=0.3.8->keybert) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=0.3.8->keybert) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers>=0.3.8->keybert) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-openai in ./.venv/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in ./.venv/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.11.15)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.11/site-packages (from llama-index-embeddings-openai) (1.51.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keybert\n",
    "%pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing story ID 7db60859-9317-4f63-97e9-611b36cacd35\n",
      "Skipping existing story ID fb0cec80-48df-41c5-90da-7abe9f65d7c2\n",
      "Skipping existing story ID 4ed272e1-c0c8-41af-9901-7df1be430dba\n",
      "Skipping existing story ID 79be11ec-d925-42ad-876c-3925cd854131\n",
      "Skipping existing story ID f9798444-14f1-434e-8534-45ede39c20a4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 173\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Run the function to fetch and store embeddings\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mfetch_and_store_tsco_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 157\u001b[0m, in \u001b[0;36mfetch_and_store_tsco_embeddings\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m embeddings_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_text_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(cleaned_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(metadata_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(rns_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(keyword_augmented_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    154\u001b[0m }\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Sentence-level embeddings\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m sentence_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mgenerate_batched_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcleaned_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m. \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    158\u001b[0m embeddings_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_level_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sentence_embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Check if content exceeds the threshold\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 157\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m embeddings_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_text_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(cleaned_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(metadata_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(rns_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_batched_embeddings(keyword_augmented_content)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    154\u001b[0m }\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Sentence-level embeddings\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m sentence_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43mgenerate_batched_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m cleaned_content\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    158\u001b[0m embeddings_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_level_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sentence_embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Check if content exceeds the threshold\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 78\u001b[0m, in \u001b[0;36mgenerate_batched_embeddings\u001b[0;34m(text, model, max_tokens)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m     77\u001b[0m     batch_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(batch)\n\u001b[0;32m---> 78\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     batch_embeddings\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(batch_embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/openai/_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/openai/_base_client.py:983\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    989\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/CODE/Zeed2/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import openai\n",
    "import numpy as np\n",
    "from keybert import KeyBERT\n",
    "from supabase import create_client, Client\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings, DocumentSummaryIndex\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "# Supabase credentials\n",
    "url = \"https://cgfvvgzbzccalpuanswp.supabase.co\"\n",
    "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNnZnZ2Z3piemNjYWxwdWFuc3dwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc5ODE1OTMsImV4cCI6MjA0MzU1NzU5M30.CyhD2YGJANqYZxw-n-B-SD4ZlU2QXjO_lX6xAVtNMCo\"\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "# KeyBERT and OpenAI API setup\n",
    "kw_model = KeyBERT()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Clean HTML content\n",
    "def clean_html_content(html_content):\n",
    "    text_no_css = re.sub(r'<style.*?>.*?</style>', ' ', html_content, flags=re.DOTALL)\n",
    "    text_no_html = re.sub(r'<.*?>', ' ', text_no_css)\n",
    "    text_content = re.sub(r'&nbsp;|&#160;|&amp;', ' ', text_no_html)\n",
    "    return re.sub(r'\\s+', ' ', text_content).strip()\n",
    "\n",
    "# Keyword extraction\n",
    "def extract_keywords(content, top_n=10):\n",
    "    keywords = kw_model.extract_keywords(content, top_n=top_n)\n",
    "    return ', '.join([keyword[0] for keyword in keywords])\n",
    "\n",
    "# Check for existing entry\n",
    "def check_existing_entry(story_id):\n",
    "    response = supabase.table('test_embeddings').select(\"story_id\").eq(\"story_id\", story_id).execute()\n",
    "    return len(response.data) > 0\n",
    "\n",
    "# Store all embeddings in the database\n",
    "def insert_all_embeddings(story_id, company_name, document_date, embeddings_dict):\n",
    "    data = {\n",
    "        \"story_id\": story_id,\n",
    "        \"company_name\": company_name,\n",
    "        \"document_date\": document_date,\n",
    "        **embeddings_dict,\n",
    "        \"event_type\": \"RNS\",\n",
    "        \"sector\": \"Technology\"\n",
    "    }\n",
    "    supabase.table('test_embeddings').insert(data).execute()\n",
    "\n",
    "\n",
    "def generate_batched_embeddings(text, model=\"text-embedding-3-large\", max_tokens=8192):\n",
    "    words = text.split()\n",
    "    batches = []\n",
    "    batch_embeddings = []\n",
    "    current_batch = []\n",
    "    current_token_count = 0\n",
    "\n",
    "\n",
    "    for word in words:\n",
    "        word_token_count = len(word) \n",
    "        if current_token_count + word_token_count > max_tokens:\n",
    "            batches.append(current_batch)\n",
    "            current_batch = [word]\n",
    "            current_token_count = word_token_count\n",
    "        else:\n",
    "            current_batch.append(word)\n",
    "            current_token_count += word_token_count\n",
    "\n",
    "    if current_batch:\n",
    "        batches.append(current_batch)\n",
    "\n",
    "    for batch in batches:\n",
    "        batch_text = \" \".join(batch)\n",
    "        response = openai.embeddings.create(input=[batch_text], model=model)\n",
    "        batch_embeddings.append(response.data[0].embedding)\n",
    "    \n",
    "    return np.mean(batch_embeddings, axis=0)\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=4000, chunk_overlap=50)\n",
    "\n",
    "\n",
    "\n",
    "def embed_and_store_large_content(content, story_id, company_name, document_date):\n",
    "    cleaned_content = clean_html_content(content)\n",
    "    keywords = extract_keywords(cleaned_content)\n",
    "    keyword_augmented_content = f\"{cleaned_content} Keywords: {keywords}\"\n",
    "\n",
    "    documents = [Document(text=keyword_augmented_content)]\n",
    "    splitter = SentenceSplitter(chunk_size=4000, chunk_overlap=50)\n",
    "    \n",
    "    Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "    Settings.node_parser = splitter\n",
    "    doc_summary_index = DocumentSummaryIndex.from_documents(documents, show_progress=True)\n",
    "    \n",
    "    nodes = doc_summary_index.get_nodes()\n",
    "    llamaindex_chunk_embeddings = [node.embedding.tolist() for node in nodes]\n",
    "    \n",
    "    embeddings_dict = {\n",
    "        \"llamaindex_chunk_embeddings\": llamaindex_chunk_embeddings,\n",
    "        # Add other embedding methods here\n",
    "    }\n",
    "    \n",
    "    insert_all_embeddings(story_id, company_name, document_date, embeddings_dict)\n",
    "    print(f\"Stored all embeddings for story ID {story_id}\")\n",
    "\n",
    "def fetch_and_store_tsco_embeddings():\n",
    "    url = \"https://api.joinzeed.com/rns/company\"\n",
    "    headers = {\"x-api-key\": \"3cnEecHxDE8qgHsTTftFPa49V5N4q2t15k4s4pqu\"}\n",
    "    params = {\"ticker\": \"TSCO.L\", \"number\": 10}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        rns_data = response.json()\n",
    "        for entry in rns_data:\n",
    "            story_id = entry.get(\"storyId\")\n",
    "            company_name = entry.get(\"issueName\", \"Unknown\")\n",
    "            document_date = entry.get(\"timestamp\")\n",
    "            \n",
    "            if check_existing_entry(story_id):\n",
    "                print(f\"Skipping existing story ID {story_id}\")\n",
    "                continue\n",
    "            \n",
    "            content_url = \"https://api.joinzeed.com/rns\"\n",
    "            content_response = requests.get(content_url, headers=headers, params={'story_id': story_id})\n",
    "            \n",
    "            if content_response.status_code == 200:\n",
    "                rns_content = content_response.json().get(\"formatted_data\", \"\")\n",
    "                \n",
    "                # Embedding different types\n",
    "                cleaned_content = clean_html_content(rns_content)\n",
    "                metadata_content = f\"Company: {company_name}, Date: {document_date}\\n{cleaned_content}\"\n",
    "                keywords = extract_keywords(cleaned_content)\n",
    "                keyword_augmented_content = f\"{cleaned_content} Keywords: {keywords}\"\n",
    "                \n",
    "                embeddings_dict = {\n",
    "                    \"cleaned_text_embedding\": generate_batched_embeddings(cleaned_content).tolist(),\n",
    "                    \"metadata_embedding\": generate_batched_embeddings(metadata_content).tolist(),\n",
    "                    \"structured_embedding\": generate_batched_embeddings(rns_content).tolist(),\n",
    "                    \"keyword_embedding\": generate_batched_embeddings(keyword_augmented_content).tolist(),\n",
    "                }\n",
    "\n",
    "                sentence_embeddings = [generate_batched_embeddings(sentence) for sentence in cleaned_content.split(\". \")]\n",
    "                embeddings_dict[\"sentence_level_embedding\"] = np.mean(sentence_embeddings, axis=0).tolist()\n",
    "\n",
    "                # Check if content exceeds the threshold\n",
    "                if len(rns_content.split()) > 8192:\n",
    "                    embed_and_store_large_content(rns_content, story_id, company_name, document_date)\n",
    "                else:\n",
    "                    # Add keyword augmented embeddings for shorter content\n",
    "                    insert_all_embeddings(story_id, company_name, document_date, embeddings_dict)\n",
    "                    print(f\"Stored embeddings for shorter content for story ID {story_id}\")\n",
    "            else:\n",
    "                print(f\"Failed to fetch full content for story ID {story_id}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function to fetch and store embeddings\n",
    "fetch_and_store_tsco_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Type: metadata_included\n",
      "Top 5 Retrieved Story IDs: []\n",
      "Precision@5: 0.00\n",
      "\n",
      "\n",
      "Embedding Type: cleaned_content\n",
      "Top 5 Retrieved Story IDs: []\n",
      "Precision@5: 0.00\n",
      "\n",
      "\n",
      "Embedding Type: raw_content\n",
      "Top 5 Retrieved Story IDs: []\n",
      "Precision@5: 0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Story Retrieval Accuracy\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from supabase import create_client, Client\n",
    "import openai\n",
    "\n",
    "# Supabase and OpenAI API Keys\n",
    "url = \"https://cgfvvgzbzccalpuanswp.supabase.co\"\n",
    "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNnZnZ2Z3piemNjYWxwdWFuc3dwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc5ODE1OTMsImV4cCI6MjA0MzU1NzU5M30.CyhD2YGJANqYZxw-n-B-SD4ZlU2QXjO_lX6xAVtNMCo\"\n",
    "\n",
    "\n",
    "# Initialize Supabase Client\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "# Define models for different embedding types\n",
    "embedding_models = {\n",
    "    'metadata_included': \"text-embedding-metadata\",\n",
    "    'cleaned_content': \"text-embedding-cleaned\",\n",
    "    'raw_content': \"text-embedding-raw\"\n",
    "}\n",
    "\n",
    "# Generate embeddings based on specified type\n",
    "def generate_embeddings(text, model):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = openai.embeddings.create(input=[text], model=model)\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "# Fetch embeddings from Supabase for evaluation\n",
    "def fetch_embeddings(embedding_type):\n",
    "    response = supabase.table('document_embeddings').select('story_id', 'embedding').execute()\n",
    "    data = [(entry['story_id'], np.array(entry['embedding'])) for entry in response.data if entry.get('embedding_type') == embedding_type]\n",
    "    return data\n",
    "\n",
    "# Precision@k calculation\n",
    "def calculate_precision_at_k(relevant, retrieved, k):\n",
    "    relevant_retrieved = [doc_id for doc_id in retrieved[:k] if doc_id in relevant]\n",
    "    precision = len(relevant_retrieved) / k\n",
    "    return precision\n",
    "\n",
    "# Find the top K closest embeddings for each embedding type\n",
    "def find_top_k_for_embedding_types(query_text, top_k=5):\n",
    "    results = {}\n",
    "    query_embedding = generate_embeddings(query_text, model=\"text-embedding-3-small\")\n",
    "    \n",
    "    for embedding_type, model in embedding_models.items():\n",
    "        embeddings_data = fetch_embeddings(embedding_type)\n",
    "        \n",
    "        similarities = [\n",
    "            (story_id, 1 - cosine(query_embedding, embedding)) \n",
    "            for story_id, embedding in embeddings_data\n",
    "        ]\n",
    "        # Sort by similarity\n",
    "        top_k_results = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        results[embedding_type] = top_k_results\n",
    "\n",
    "    return results\n",
    "\n",
    "# Compare embedding types\n",
    "def compare_embedding_types(query_text, relevant_story_ids, top_k=5):\n",
    "    results = find_top_k_for_embedding_types(query_text, top_k=top_k)\n",
    "    \n",
    "    for embedding_type, top_k_results in results.items():\n",
    "        retrieved_story_ids = [story_id for story_id, _ in top_k_results]\n",
    "        precision_at_k = calculate_precision_at_k(relevant_story_ids, retrieved_story_ids, k=top_k)\n",
    "        \n",
    "        print(f\"Embedding Type: {embedding_type}\")\n",
    "        print(f\"Top {top_k} Retrieved Story IDs: {retrieved_story_ids}\")\n",
    "        print(f\"Precision@{top_k}: {precision_at_k:.2f}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Example Usage\n",
    "query_text = \"What is GraniteShare up to? What are their biggest ETPs?\"\n",
    "relevant_story_ids = ['123', '456', '789']  # Replace with actual relevant story IDs\n",
    "compare_embedding_types(query_text, relevant_story_ids, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity analysis for embedding types\n",
    "def cosine_similarity_analysis(query_text, top_k=5):\n",
    "    query_embedding = generate_embeddings(query_text, model=\"text-embedding-3-small\")\n",
    "    similarity_scores = {}\n",
    "\n",
    "    for embedding_type, model in embedding_models.items():\n",
    "        embeddings_data = fetch_embeddings(embedding_type)\n",
    "        \n",
    "        similarities = [\n",
    "            (story_id, 1 - cosine(query_embedding, embedding)) \n",
    "            for story_id, embedding in embeddings_data\n",
    "        ]\n",
    "        # Sort by similarity\n",
    "        top_k_results = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        avg_similarity = np.mean([similarity for _, similarity in top_k_results])\n",
    "        \n",
    "        similarity_scores[embedding_type] = avg_similarity\n",
    "        print(f\"Embedding Type: {embedding_type}\")\n",
    "        print(f\"Average Cosine Similarity for Top {top_k}: {avg_similarity:.4f}\")\n",
    "        print(\"Top K Results:\")\n",
    "        for story_id, similarity in top_k_results:\n",
    "            print(f\" - Story ID: {story_id}, Similarity: {similarity:.4f}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Example Usage\n",
    "cosine_similarity_analysis(query_text, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt with top K results and query GPT for each embedding type\n",
    "def response_analysis_with_gpt(query_text, top_k=5):\n",
    "    for embedding_type, model in embedding_models.items():\n",
    "        top_k_results = find_top_k_for_embedding_types(query_text, top_k=top_k)[embedding_type]\n",
    "        prompt = f\"User Query: {query_text}\\n\\nRelevant Information:\\n\"\n",
    "        \n",
    "        for story_id, similarity in top_k_results:\n",
    "            content = fetch_content_from_document_store(story_id)\n",
    "            prompt += f\"Story ID: {story_id}, Similarity: {similarity}\\nContent: {content}\\n\\n\"\n",
    "\n",
    "        # Query GPT with the generated prompt\n",
    "        gpt_response = query_gpt_with_prompt(prompt)\n",
    "        \n",
    "        print(f\"Embedding Type: {embedding_type}\")\n",
    "        print(\"GPT Response:\\n\", gpt_response)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example Usage\n",
    "response_analysis_with_gpt(query_text, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
